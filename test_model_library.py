"""
Test Model Library

This set of tests tries to evaluate all of the various types of models and
model elements that PySD should be able to handle. It does so by executing
the models and comparing their outputs with a set of outputs generated by the
program in which the models were written.

These tests are part of a common system dynamics test suite, that is used by
a number of developers to help develop their own system dynamics tools, and
is available on github at https://github.com/SDXorg/test-models.

The PySD project repository imports these tests as a submodule, and as such the
tests are versioned with the version of the PySD project, so that the two
modules can develop in parallel.

Arguments
---------
-v --verbose : (optional)
    Include this flag to ask for more elaborated error messages
-n --number : int or comma separated list of ints
    Select which tests to run by number

Examples:
To run the full test suite in concise mode:
>>> python test_model_library.py

To run the third test:
>>> python test_model_library.py -n3

To run the third and fifth tests:
>>> python test_model_library.py -n3,5

To run the full test suite in verbose mode:
>>> python test_model_library.py -v

To run test 3 in verbose mode:
>>> python test_model_library.py -v -n3
"""

import glob
import os.path
import traceback
from parsimonious.exceptions import ParseError, IncompleteParseError, VisitationError
import pandas as pd
import pysd
import sys
import timeit
import argparse

# Todo: add option to run only vensim, xmile, or all tests
# Todo: properly format subscript arrays for checking against canonical output

parser = argparse.ArgumentParser()
parser.add_argument('-n','--number', help='which test to run')
parser.add_argument('-v','--verbose', help='displays lots of error messages', action="store_true")
args = parser.parse_args()

#load test models
test_dir = 'tests/test-models/'
vensim_testfiles = glob.glob(test_dir+'*/*/*.mdl')
vensim_testfiles = glob.glob(test_dir+'tests/*/*.mdl')
#xmile_testfiles = glob.glob(test_dir+'*/*/*.xmile')
xmile_testfiles = []
testfiles = {number: testfile for number, testfile in enumerate(vensim_testfiles + xmile_testfiles)}

if args.number:
    numbers = map(int,args.number.split(','))
    testfiles = {int(number): testfiles[int(number)] for number in numbers}


print "Testing module at location: %s\n"%pysd.__file__
err_str = '\n\n'
threshold = 1

success_count = 0
err_count = 0
fail_count = 0

starttime = timeit.time.time()

# Todo: refactor to break out each step into its own try/except?

for i, modelfile in testfiles.iteritems():
    status_str = ''

    try:
        if modelfile[-3:] == "mdl":
            model = pysd.read_vensim(modelfile)
            status_str += 'Loaded Model, '
        elif modelfile[-5:] == "xmile":
            model = pysd.read_xmile(modelfile)
            status_str += 'Loaded Model, '

        directory = os.path.dirname(modelfile)
        output_basename = directory+'/output'
        #os ifexistss csv, import, else import tab.


        canon = pd.read_csv(directory+'/output.csv', index_col='Time')

        return_columns = [pysd.builder.make_python_identifier(x) for x in canon.columns.tolist()]
        canon.columns = return_columns #rename the columns we brought in so they match to the model output

        status_str += 'Looking for output columns: '+', '.join(return_columns)

        output = model.run(return_columns=return_columns)

        status_str += 'Ran Model, got columns'+', '.join(output.columns.tolist())
        
        assert (canon-output).max().max() < 1
        
        print '.',
        success_count += 1
        
    except ParseError as e:
        print 'F',
        
        err_str += '='*60 + '\n'
        err_str += '%i | Test Failure of: %s \n'%(i,modelfile)
        err_str += '-'*60 + '\n'
        err_str += 'Parsing Error at line: %i, column%i.\n'%(e.line(), e.column())
        err_str += 'On rule: %s \n\n'%e.expr.__repr__()
        err_str += str(e)
        #err_str += e.text.splitlines()[e.line()-1] + '\n' #line numbers are 1 based, most likely
        #err_str += '^'.rjust(e.column())
        err_str += '\n\n'

        fail_count += 1

    except VisitationError as e:
        print 'F',

        err_str += '='*60 + '\n'
        err_str += '%i | Test Failure of: %s \n'%(i,modelfile)
        err_str += '-'*60 + '\n'
        err_str += str(e.args[0]) if args.verbose else '\n'.join(str(e.args[0]).splitlines()[:10])+'\n...\n add flag -v to see more'
        err_str += '\n\n'

        fail_count += 1
        
    except IOError as e:
        print 'E',
        
        err_str += '='*60 + '\n'
        err_str += '%i | Test Error attempting: %s \n'%(i,modelfile)
        err_str += '-'*60 + '\n'
        err_str += 'Could not load canonical output\n'
        err_str += '\n\n'

        err_count += 1

    except AssertionError as e:
        print 'F',

        err_str += '='*60 + '\n'
        err_str += '%i | Test Failure of: %s \n'%(i,modelfile)
        err_str += '-'*60 + '\n'
        err_str += 'Model output does not match canon.\n'
        err_str += 'Variable       Maximum Discrepancy\n'
        err_str += str((canon-output).max())
        err_str += '\n\n'

        fail_count += 1

    except Exception as e:
        print 'E',
        err_str += '='*60 + '\n'
        err_str += '%i | Unknown issue with: %s \n'%(i,modelfile)
        err_str += '-'*60 + '\n'
        err_str += status_str + '\n'
        err_str += str(e.args[0])
        err_str += '\n\n'

        err_count += 1

endtime = timeit.time.time()

err_str += '='*60 + '\n'
err_str += 'Attempted %i tests in %.02f seconds \n'%(len(testfiles), (endtime-starttime))
err_str += '%i Successes, %i Failures, %i Errors'%(success_count, fail_count, err_count)

print err_str